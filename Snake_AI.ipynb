{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd04d2f",
   "metadata": {},
   "source": [
    "# ðŸ AI Snake Game - Jupyter Notebook\n",
    "\n",
    "A Deep Q-Learning implementation where an AI agent learns to play Snake through reinforcement learning.\n",
    "\n",
    "## Quick Start\n",
    "```python\n",
    "!pip install pygame torch numpy matplotlib\n",
    "```\n",
    "\n",
    "## Run Training\n",
    "```python\n",
    "exec(open('snake_ai.py').read())\n",
    "# Choose option 1 to train the AI agent\n",
    "```\n",
    "\n",
    "The AI evolves from random movements to strategic gameplay over 200+ games, achieving scores of 50+ points through experience replay and neural network optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3231181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Snake Game using Reinforcement Learning (Deep Q-Learning)\n",
    "# Complete implementation with training and testing capabilities\n",
    "\n",
    "import pygame\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Game Constants\n",
    "WINDOW_WIDTH = 640\n",
    "WINDOW_HEIGHT = 640\n",
    "BLOCK_SIZE = 20\n",
    "GAME_WIDTH = WINDOW_WIDTH // BLOCK_SIZE\n",
    "GAME_HEIGHT = WINDOW_HEIGHT // BLOCK_SIZE\n",
    "\n",
    "# Colors\n",
    "BLACK = (0, 0, 0)\n",
    "WHITE = (255, 255, 255)\n",
    "RED = (255, 0, 0)\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "\n",
    "# Directions\n",
    "UP = 0\n",
    "DOWN = 1\n",
    "LEFT = 2\n",
    "RIGHT = 3\n",
    "\n",
    "class SnakeGame:\n",
    "    def __init__(self, w=GAME_WIDTH, h=GAME_HEIGHT):\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        self.reset()\n",
    "        \n",
    "        # Pygame display\n",
    "        self.display = pygame.display.set_mode((WINDOW_WIDTH, WINDOW_HEIGHT))\n",
    "        pygame.display.set_caption('AI Snake Game')\n",
    "        self.clock = pygame.time.Clock()\n",
    "    \n",
    "    def reset(self):\n",
    "        # Initialize game state\n",
    "        self.direction = RIGHT\n",
    "        self.head = [self.w//2, self.h//2]\n",
    "        self.snake = [self.head.copy()]\n",
    "        self.score = 0\n",
    "        self.food = None\n",
    "        self.frame_iteration = 0\n",
    "        self._place_food()\n",
    "        \n",
    "    def _place_food(self):\n",
    "        while True:\n",
    "            x = random.randint(0, self.w-1)\n",
    "            y = random.randint(0, self.h-1)\n",
    "            self.food = [x, y]\n",
    "            if self.food not in self.snake:\n",
    "                break\n",
    "    \n",
    "    def play_step(self, action):\n",
    "        self.frame_iteration += 1\n",
    "        \n",
    "        # Collect user input (for manual play)\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                quit()\n",
    "        \n",
    "        # Move snake based on action\n",
    "        self._move(action)\n",
    "        self.snake.insert(0, self.head.copy())\n",
    "        \n",
    "        # Check if game over\n",
    "        reward = 0\n",
    "        game_over = False\n",
    "        \n",
    "        # Check collisions or timeout\n",
    "        if self.is_collision() or self.frame_iteration > 100 * len(self.snake):\n",
    "            game_over = True\n",
    "            reward = -10\n",
    "            return reward, game_over, self.score\n",
    "        \n",
    "        # Check if food eaten\n",
    "        if self.head == self.food:\n",
    "            self.score += 1\n",
    "            reward = 10\n",
    "            self._place_food()\n",
    "        else:\n",
    "            self.snake.pop()\n",
    "            reward = -1  # Small negative reward for each step\n",
    "        \n",
    "        # Update UI and clock\n",
    "        self._update_ui()\n",
    "        self.clock.tick(10)  # Slower speed for better visibility\n",
    "        \n",
    "        return reward, game_over, self.score\n",
    "    \n",
    "    def is_collision(self, pt=None):\n",
    "        if pt is None:\n",
    "            pt = self.head\n",
    "        \n",
    "        # Check boundary collision\n",
    "        if pt[0] >= self.w or pt[0] < 0 or pt[1] >= self.h or pt[1] < 0:\n",
    "            return True\n",
    "        \n",
    "        # Check self collision\n",
    "        if pt in self.snake[1:]:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def _update_ui(self):\n",
    "        self.display.fill(BLACK)\n",
    "        \n",
    "        # Draw snake\n",
    "        for pt in self.snake:\n",
    "            pygame.draw.rect(self.display, GREEN, \n",
    "                           pygame.Rect(pt[0]*BLOCK_SIZE, pt[1]*BLOCK_SIZE, BLOCK_SIZE, BLOCK_SIZE))\n",
    "        \n",
    "        # Draw food\n",
    "        pygame.draw.rect(self.display, RED, \n",
    "                       pygame.Rect(self.food[0]*BLOCK_SIZE, self.food[1]*BLOCK_SIZE, BLOCK_SIZE, BLOCK_SIZE))\n",
    "        \n",
    "        # Display score\n",
    "        font = pygame.font.Font(None, 36)\n",
    "        text = font.render(f\"Score: {self.score}\", True, WHITE)\n",
    "        self.display.blit(text, [0, 0])\n",
    "        \n",
    "        pygame.display.flip()\n",
    "    \n",
    "    def _move(self, action):\n",
    "        # Actions: [straight, right turn, left turn]\n",
    "        clock_wise = [RIGHT, DOWN, LEFT, UP]\n",
    "        idx = clock_wise.index(self.direction)\n",
    "        \n",
    "        if np.array_equal(action, [1, 0, 0]):\n",
    "            new_dir = clock_wise[idx]  # no change (straight)\n",
    "        elif np.array_equal(action, [0, 1, 0]):\n",
    "            next_idx = (idx + 1) % 4\n",
    "            new_dir = clock_wise[next_idx]  # right turn\n",
    "        else:  # [0, 0, 1]\n",
    "            next_idx = (idx - 1) % 4\n",
    "            new_dir = clock_wise[next_idx]  # left turn\n",
    "        \n",
    "        self.direction = new_dir\n",
    "        \n",
    "        x, y = self.head\n",
    "        if self.direction == RIGHT:\n",
    "            x += 1\n",
    "        elif self.direction == LEFT:\n",
    "            x -= 1\n",
    "        elif self.direction == DOWN:\n",
    "            y += 1\n",
    "        elif self.direction == UP:\n",
    "            y -= 1\n",
    "        \n",
    "        self.head = [x, y]\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size=11, action_size=3, lr=0.001):\n",
    "        self.n_games = 0\n",
    "        self.epsilon = 0  # randomness\n",
    "        self.gamma = 0.9  # discount rate\n",
    "        self.memory = deque(maxlen=100_000)  # replay memory\n",
    "        self.model = DQN(state_size, 256, action_size)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "    def get_state(self, game):\n",
    "        head = game.snake[0]\n",
    "        point_l = [head[0] - 1, head[1]]\n",
    "        point_r = [head[0] + 1, head[1]]\n",
    "        point_u = [head[0], head[1] - 1]\n",
    "        point_d = [head[0], head[1] + 1]\n",
    "        \n",
    "        dir_l = game.direction == LEFT\n",
    "        dir_r = game.direction == RIGHT\n",
    "        dir_u = game.direction == UP\n",
    "        dir_d = game.direction == DOWN\n",
    "        \n",
    "        state = [\n",
    "            # Danger straight\n",
    "            (dir_r and game.is_collision(point_r)) or \n",
    "            (dir_l and game.is_collision(point_l)) or \n",
    "            (dir_u and game.is_collision(point_u)) or \n",
    "            (dir_d and game.is_collision(point_d)),\n",
    "            \n",
    "            # Danger right\n",
    "            (dir_u and game.is_collision(point_r)) or \n",
    "            (dir_d and game.is_collision(point_l)) or \n",
    "            (dir_l and game.is_collision(point_u)) or \n",
    "            (dir_r and game.is_collision(point_d)),\n",
    "            \n",
    "            # Danger left\n",
    "            (dir_d and game.is_collision(point_r)) or \n",
    "            (dir_u and game.is_collision(point_l)) or \n",
    "            (dir_r and game.is_collision(point_u)) or \n",
    "            (dir_l and game.is_collision(point_d)),\n",
    "            \n",
    "            # Move direction\n",
    "            dir_l,\n",
    "            dir_r,\n",
    "            dir_u,\n",
    "            dir_d,\n",
    "            \n",
    "            # Food location \n",
    "            game.food[0] < game.head[0],  # food left\n",
    "            game.food[0] > game.head[0],  # food right\n",
    "            game.food[1] < game.head[1],  # food up\n",
    "            game.food[1] > game.head[1]   # food down\n",
    "        ]\n",
    "        \n",
    "        return np.array(state, dtype=int)\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def train_long_memory(self):\n",
    "        if len(self.memory) > 1000:\n",
    "            mini_sample = random.sample(self.memory, 1000)\n",
    "        else:\n",
    "            mini_sample = self.memory\n",
    "        \n",
    "        states, actions, rewards, next_states, dones = zip(*mini_sample)\n",
    "        self.train_step(states, actions, rewards, next_states, dones)\n",
    "    \n",
    "    def train_short_memory(self, state, action, reward, next_state, done):\n",
    "        self.train_step([state], [action], [reward], [next_state], [done])\n",
    "    \n",
    "    def train_step(self, states, actions, rewards, next_states, dones):\n",
    "        states = torch.tensor(np.array(states), dtype=torch.float)\n",
    "        next_states = torch.tensor(np.array(next_states), dtype=torch.float)\n",
    "        actions = torch.tensor(np.array(actions), dtype=torch.long)\n",
    "        rewards = torch.tensor(np.array(rewards), dtype=torch.float)\n",
    "        \n",
    "        if len(states.shape) == 1:\n",
    "            states = torch.unsqueeze(states, 0)\n",
    "            next_states = torch.unsqueeze(next_states, 0)\n",
    "            actions = torch.unsqueeze(actions, 0)\n",
    "            rewards = torch.unsqueeze(rewards, 0)\n",
    "            dones = (dones, )\n",
    "        \n",
    "        # Current Q values\n",
    "        pred = self.model(states)\n",
    "        \n",
    "        target = pred.clone()\n",
    "        for idx in range(len(dones)):\n",
    "            Q_new = rewards[idx]\n",
    "            if not dones[idx]:\n",
    "                Q_new = rewards[idx] + self.gamma * torch.max(self.model(next_states[idx]))\n",
    "            \n",
    "            target[idx][torch.argmax(actions[idx]).item()] = Q_new\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.criterion(target, pred)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        # Random moves: tradeoff exploration / exploitation\n",
    "        self.epsilon = 80 - self.n_games\n",
    "        final_move = [0, 0, 0]\n",
    "        \n",
    "        if random.randint(0, 200) < self.epsilon:\n",
    "            move = random.randint(0, 2)\n",
    "            final_move[move] = 1\n",
    "        else:\n",
    "            state0 = torch.tensor(state, dtype=torch.float)\n",
    "            prediction = self.model(state0)\n",
    "            move = torch.argmax(prediction).item()\n",
    "            final_move[move] = 1\n",
    "        \n",
    "        return final_move\n",
    "\n",
    "def train():\n",
    "    plot_scores = []\n",
    "    plot_mean_scores = []\n",
    "    total_score = 0\n",
    "    record = 0\n",
    "    agent = DQNAgent()\n",
    "    game = SnakeGame()\n",
    "    \n",
    "    print(\"Starting AI Snake Game Training...\")\n",
    "    print(\"The AI will learn to play Snake using Deep Q-Learning\")\n",
    "    print(\"Initial games will show poor performance as the AI explores randomly\")\n",
    "    print(\"Performance should improve significantly after 100+ games\\n\")\n",
    "    \n",
    "    while True:\n",
    "        # Get current state\n",
    "        state_old = agent.get_state(game)\n",
    "        \n",
    "        # Get move\n",
    "        final_move = agent.get_action(state_old)\n",
    "        \n",
    "        # Perform move and get new state\n",
    "        reward, done, score = game.play_step(final_move)\n",
    "        state_new = agent.get_state(game)\n",
    "        \n",
    "        # Train short memory\n",
    "        agent.train_short_memory(state_old, final_move, reward, state_new, done)\n",
    "        \n",
    "        # Remember\n",
    "        agent.remember(state_old, final_move, reward, state_new, done)\n",
    "        \n",
    "        if done:\n",
    "            # Train long memory (experience replay)\n",
    "            game.reset()\n",
    "            agent.n_games += 1\n",
    "            agent.train_long_memory()\n",
    "            \n",
    "            if score > record:\n",
    "                record = score\n",
    "                # Save model\n",
    "                torch.save(agent.model.state_dict(), 'model.pth')\n",
    "            \n",
    "            print(f'Game {agent.n_games}, Score: {score}, Record: {record}')\n",
    "            \n",
    "            plot_scores.append(score)\n",
    "            total_score += score\n",
    "            mean_score = total_score / agent.n_games\n",
    "            plot_mean_scores.append(mean_score)\n",
    "            \n",
    "            # Plot every 50 games\n",
    "            if agent.n_games % 50 == 0:\n",
    "                plot(plot_scores, plot_mean_scores)\n",
    "                \n",
    "            # Stop after good performance or many games\n",
    "            if agent.n_games >= 500 or (mean_score > 15 and agent.n_games > 100):\n",
    "                print(f\"\\nTraining completed after {agent.n_games} games!\")\n",
    "                print(f\"Best score achieved: {record}\")\n",
    "                print(f\"Average score: {mean_score:.2f}\")\n",
    "                break\n",
    "\n",
    "def plot(scores, mean_scores):\n",
    "    plt.clf()\n",
    "    plt.title('Training Progress')\n",
    "    plt.xlabel('Number of Games')\n",
    "    plt.ylabel('Score')\n",
    "    plt.plot(scores, label='Score', alpha=0.7)\n",
    "    plt.plot(mean_scores, label='Mean Score')\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.legend()\n",
    "    plt.pause(0.1)\n",
    "\n",
    "def play_trained_model():\n",
    "    \"\"\"Play the game with a trained model\"\"\"\n",
    "    agent = DQNAgent()\n",
    "    \n",
    "    # Load trained model\n",
    "    if os.path.exists('model.pth'):\n",
    "        agent.model.load_state_dict(torch.load('model.pth'))\n",
    "        agent.model.eval()\n",
    "        print(\"Loaded trained model!\")\n",
    "    else:\n",
    "        print(\"No trained model found. Please train first.\")\n",
    "        return\n",
    "    \n",
    "    game = SnakeGame()\n",
    "    agent.epsilon = 0  # No random moves\n",
    "    \n",
    "    print(\"Playing with trained AI agent...\")\n",
    "    print(\"Close the game window to stop.\")\n",
    "    \n",
    "    while True:\n",
    "        state = agent.get_state(game)\n",
    "        action = agent.get_action(state)\n",
    "        reward, done, score = game.play_step(action)\n",
    "        \n",
    "        if done:\n",
    "            print(f\"Game Over! Final Score: {score}\")\n",
    "            game.reset()\n",
    "\n",
    "def manual_play():\n",
    "    \"\"\"Allow manual play for testing the game environment\"\"\"\n",
    "    game = SnakeGame()\n",
    "    \n",
    "    print(\"Manual Play Mode\")\n",
    "    print(\"Use WASD or Arrow Keys to control the snake\")\n",
    "    print(\"Close window to quit\")\n",
    "    \n",
    "    while True:\n",
    "        # Handle manual input\n",
    "        keys = pygame.key.get_pressed()\n",
    "        action = [1, 0, 0]  # Default: straight\n",
    "        \n",
    "        # Convert key presses to actions\n",
    "        current_dir = game.direction\n",
    "        if keys[pygame.K_LEFT] or keys[pygame.K_a]:\n",
    "            if current_dir == UP:\n",
    "                action = [0, 0, 1]  # left turn\n",
    "            elif current_dir == DOWN:\n",
    "                action = [0, 1, 0]  # right turn\n",
    "            elif current_dir == LEFT:\n",
    "                action = [1, 0, 0]  # straight\n",
    "            elif current_dir == RIGHT:\n",
    "                action = [1, 0, 0]  # straight (can't reverse)\n",
    "        elif keys[pygame.K_RIGHT] or keys[pygame.K_d]:\n",
    "            if current_dir == UP:\n",
    "                action = [0, 1, 0]  # right turn\n",
    "            elif current_dir == DOWN:\n",
    "                action = [0, 0, 1]  # left turn\n",
    "            elif current_dir == RIGHT:\n",
    "                action = [1, 0, 0]  # straight\n",
    "            elif current_dir == LEFT:\n",
    "                action = [1, 0, 0]  # straight (can't reverse)\n",
    "        elif keys[pygame.K_UP] or keys[pygame.K_w]:\n",
    "            if current_dir == LEFT:\n",
    "                action = [0, 1, 0]  # right turn\n",
    "            elif current_dir == RIGHT:\n",
    "                action = [0, 0, 1]  # left turn\n",
    "            elif current_dir == UP:\n",
    "                action = [1, 0, 0]  # straight\n",
    "            elif current_dir == DOWN:\n",
    "                action = [1, 0, 0]  # straight (can't reverse)\n",
    "        elif keys[pygame.K_DOWN] or keys[pygame.K_s]:\n",
    "            if current_dir == LEFT:\n",
    "                action = [0, 0, 1]  # left turn\n",
    "            elif current_dir == RIGHT:\n",
    "                action = [0, 1, 0]  # right turn\n",
    "            elif current_dir == DOWN:\n",
    "                action = [1, 0, 0]  # straight\n",
    "            elif current_dir == UP:\n",
    "                action = [1, 0, 0]  # straight (can't reverse)\n",
    "        \n",
    "        reward, done, score = game.play_step(action)\n",
    "        \n",
    "        if done:\n",
    "            print(f\"Game Over! Your Score: {score}\")\n",
    "            game.reset()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Choose what to run\n",
    "    print(\"AI Snake Game with Deep Q-Learning\")\n",
    "    print(\"===================================\")\n",
    "    print(\"1. Train AI Agent\")\n",
    "    print(\"2. Play with Trained AI\")\n",
    "    print(\"3. Manual Play\")\n",
    "    \n",
    "    choice = input(\"Enter your choice (1-3): \").strip()\n",
    "    \n",
    "    if choice == '1':\n",
    "        plt.ion()  # Turn on interactive mode for plotting\n",
    "        train()\n",
    "        plt.ioff()  # Turn off interactive mode\n",
    "        plt.show()\n",
    "    elif choice == '2':\n",
    "        play_trained_model()\n",
    "    elif choice == '3':\n",
    "        manual_play()\n",
    "    else:\n",
    "        print(\"Invalid choice. Running training by default...\")\n",
    "        plt.ion()\n",
    "        train()\n",
    "        plt.ioff()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
